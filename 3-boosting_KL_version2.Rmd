---
title: "1-preparation"
output: html_document
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---
# Load package
```{r}
library (tidyverse)
library (FDboost)
library (epiR)
library (mltest)
library (pROC)
library (dcurves)

source("common_functions.R")
```
# Import files

```{r}
df <- readRDS ("merged_dat.RDS")

# Remove segment angles
df <- df[!grepl("Head|Thorax|Pelvis|Foot|Elbows_Y|Elbows_Z", names (df))]

df$cycle <- NULL
```

# Create train test split

```{r}

set.seed(456)
train_id <- caret::createDataPartition(
  y = df$group,
  times = 1,
  p = 0.7, # 70-30 split
  list = TRUE)[[1]]

test_id <- !(1:length(df$id) %in% train_id)

train_test_split_mat <- function (x, id = train_id) {
  
  x[id,]
}

train_test_split_vec <- function (x, id = train_id) {
  
  x[id]
}

train_df <- df %>%
  map_if(is.matrix, train_test_split_mat, train_id) %>%
  map_at(c(1:9), train_test_split_vec, train_id)

test_df <- df %>%
  map_if(is.matrix, train_test_split_mat, test_id) %>%
  map_at(c(1:9), train_test_split_vec, test_id)


train_df$kl_severity <- factor (train_df$kl_severity)
test_df$kl_severity <- factor (test_df$kl_severity)
df$kl_severity <- factor (df$kl_severity)

df$class <- 
  train_df$class <- 
  test_df$class <- 
  factor(levels(train_df$kl_severity)[-nlevels(train_df$kl_severity)])

df$cycle <- train_df$cycle <-  test_df$cycle <- 1:101

```


# Scaling

```{r}
fun_names <- grep("_Z|X|Y", names (train_df), value = TRUE)

test_df[fun_names] <- test_df[fun_names] %>% 
  map (scale, center = TRUE, scale = FALSE)

train_df[fun_names] <- train_df[fun_names] %>%
  map (scale, center = TRUE, scale = FALSE)

df[fun_names] <- df[fun_names] %>%
  map (scale, center = TRUE, scale = FALSE)

```


# Model

## Formula

```{r}
lhs <- "kl_severity ~ "

rhs1 <- paste0("bsignal(", fun_names, 
                   ", s = cycle, differences = 1)")
rhs2 <- paste0(rhs1, "%O% bols(class, df = 3, contrasts.arg = 'contr.dummy')")
rhs <- paste(rhs2, collapse = " + ")

form <- as.formula( paste0(lhs, rhs) )

```

## Based on bootstrapping all data

```{r}
mod <- readRDS("mod_kl.RDS")$mod
boot_list <- readRDS("mod_kl.RDS")$boot_list
```


```{r}

mod <- FDboost(
  formula = form, 
  data = df, 
  timeformula = NULL, 
  family = Multinomial(), 
  # define the boosting specific parameters
  # mstop:  set to a large number, such as 1000.
  #         We will choose the optimal stoppting
  #         iteration in the next step via cross-validation
  # nu:     learning rate: 0.1 is a good default, which 
  #         works for most cases
  control = boost_control(mstop = 500, 
                          nu = 0.1)
)


# through all mstop iterations, whether we should have
# stopped early as the algorithm might already have
# overfitted
set.seed(1)
folds = cv(rep(1, length(unique(mod$id))), 
           type = "kfold", B = 10)
cvr = cvrisk(mod, folds = folds)
# plot the cross-validation search and 
# the best stopping iteration
plot(cvr)
# redefine the model and set it to the best stopping
# iteration (which is done inplace): 
(best_iteration = mstop(cvr))
mod[best_iteration]
# plot the important predictors
plot(mboost::varimp(mod))
# plot the estimated effects of the model
# hot fix:
which <- intersect(1:length(mod$baselearner),
                   c(0, selected(mod)))
coefs <- coef(mod, which=which)[[2]]
for(cf in coefs){
  matplot(cf$x, cf$value, type="l", main = 
            gsub("bsignal\\((.*)\\) %.*", "\\1", cf$main),
          xlab = cf$xlab, ylab = "Partial effect")
}

```

### Validation

```{r}
B = 1000

set.seed(1)
boot_folds = cv(rep(1, length(unique(mod$id))), 
           type = "bootstrap", B = B)


boot_list <- cvrisk(mod, 
                     folds = boot_folds, 
                     fun = function(object) predict(object, 
                                                    type = "response"))

boot_list2 <- boot_list %>%
  map(~apply(.x,1,which.max)) %>%
  bind_cols()

boot_list2$outcome <- as.numeric (df$kl_severity)
boot_list2 <- boot_list2 %>%
  dplyr::select(outcome, everything ())


# KL0 vs all
o <- ifelse (boot_list2$outcome == 1, 0, 1) # 0 is healthy, 1 is OA

val_list <- vector("list", B)

for (n in 1:B) {
  
  p <- ifelse (boot_list2[, n + 1] == 1, 0, 1) %>% as.numeric
  
  tab <- table(p, o)
  a <- tab[2,2]
  b <- tab[2,1]
  c <- tab[1,2]
  d <- tab[1,1]

 val_list[[n]] <- epi.tests(c(a, b, c, d), method = "exact", digits = 2, conf.level = 0.95)$detail[,c(1,2)]
  
}



val_df1 <- bind_rows(val_list, .id = "boot") %>%
  filter (statistic %in% c("se", "sp", "pv.pos", "pv.neg", 
                           "lr.pos", "lr.neg", "diag.ac", "diag.or")) %>%
  group_by(statistic) %>%
  summarise (Est = mean (est),
             LB = quantile (est, probs = 0.025),
             UB = quantile (est, probs = 0.975)) %>%
  mutate_if (is.numeric, round, 2)


# KL2 vs all
o <- ifelse (boot_list2$outcome == 2, 1, 0) # 2 is KL2

val_list <- vector("list", B)

for (n in 1:B) {
  
  p <- ifelse (boot_list2[, n + 1] == 2, 1, 0) %>% as.numeric
  
  tab <- table(p, o)
  a <- tab[2,2]
  b <- tab[2,1]
  c <- tab[1,2]
  d <- tab[1,1]

 val_list[[n]] <- epi.tests(c(a, b, c, d), method = "exact", digits = 2, conf.level = 0.95)$detail[,c(1,2)]
  
}



val_df2 <- bind_rows(val_list, .id = "boot") %>%
  filter (statistic %in% c("se", "sp", "pv.pos", "pv.neg", 
                           "lr.pos", "lr.neg", "diag.ac", "diag.or")) %>%
  group_by(statistic) %>%
  summarise (Est = mean (est),
             LB = quantile (est, probs = 0.025),
             UB = quantile (est, probs = 0.975)) %>%
  mutate_if (is.numeric, round, 2)


# KL3 vs all
o <- ifelse (boot_list2$outcome == 3, 1, 0) # 3 is KL3

val_list <- vector("list", B)

for (n in 1:B) {
  
  p <- ifelse (boot_list2[, n + 1] == 3, 1, 0) %>% as.numeric
  
  tab <- table(p, o)
  a <- tab[2,2]
  b <- tab[2,1]
  c <- tab[1,2]
  d <- tab[1,1]

 val_list[[n]] <- epi.tests(c(a, b, c, d), method = "exact", digits = 2, conf.level = 0.95)$detail[,c(1,2)]
  
}



val_df3 <- bind_rows(val_list, .id = "boot") %>%
  filter (statistic %in% c("se", "sp", "pv.pos", "pv.neg", 
                           "lr.pos", "lr.neg", "diag.ac", "diag.or")) %>%
  group_by(statistic) %>%
  summarise (Est = mean (est),
             LB = quantile (est, probs = 0.025),
             UB = quantile (est, probs = 0.975)) %>%
  mutate_if (is.numeric, round, 2)


# KL4 vs all
o <- ifelse (boot_list2$outcome == 4, 1, 0) # 4 is KL4

val_list <- vector("list", B)

for (n in 1:B) {
  
  p <- ifelse (boot_list2[, n + 1] == 4, 1, 0) %>% as.numeric
  
  tab <- table(p, o)
  a <- tab[2,2]
  b <- tab[2,1]
  c <- tab[1,2]
  d <- tab[1,1]

 val_list[[n]] <- epi.tests(c(a, b, c, d), method = "exact", digits = 2, conf.level = 0.95)$detail[,c(1,2)]
  
}



val_df4 <- bind_rows(val_list, .id = "boot") %>%
  filter (statistic %in% c("se", "sp", "pv.pos", "pv.neg", 
                           "lr.pos", "lr.neg", "diag.ac", "diag.or")) %>%
  group_by(statistic) %>%
  summarise (Est = mean (est),
             LB = quantile (est, probs = 0.025),
             UB = quantile (est, probs = 0.975)) %>%
  mutate_if (is.numeric, round, 2)
```

### Plot the prediction results

```{r}
val_df <- bind_rows(val_df1, val_df2, val_df3, val_df4) %>%
  mutate (Type = rep(c("KL0 vs all", "KL2 vs all", "KL3 vs all", "KL4 vs all"), each = 8) %>%
            factor (levels = c("KL0 vs all", "KL2 vs all", "KL3 vs all", "KL4 vs all"))) %>%
  mutate (Statistic = factor (statistic, 
                              levels = c("se", "sp", "pv.neg", "pv.pos",
                                         "lr.neg", "lr.pos", "diag.ac", "diag.or"),
                              labels = c("Sensitivity", "Specificity",
                                         "Negative predictive value",
                                         "Positive predictive value",
                                         "Negative likelihood ratio",
                                         "Positive likelihood ratio",
                                         "Accuracy",
                                         "Odds ratio"))) %>%
  dplyr::select(Type, Statistic, everything (), - statistic)

val_df <- val_df %>%
  mutate (value = glue::glue("{Est} ({LB}, {UB})")) %>%
  dplyr::select(Type, Statistic, value) %>%
  pivot_wider(values_from = value,
              names_from = Type)
```


# Save results

```{r}
saveRDS(list (mod = mod, boot_list = boot_list), "mod_kl.RDS")
```

```{r}
mod_kl <- readRDS("mod_kl.RDS")
mod <- mod_kl$mod
boot_list <- mod_kl$boot_list
```


# Plot results

## Variable importance

```{r}
vp_df <- data.frame (varimp(mod)) %>%
  mutate (variable = str_remove(variable, "class, ")) %>%
  filter (reduction != 0) %>%
  arrange (desc (reduction)) %>%
  slice (1:9) %>%
  dplyr::select (-blearner)  %>%
  mutate (reduction = round (reduction, 2),
          selfreq = round (selfreq, 2))

vp_df2 <- data.frame (varimp(mod)) %>%
  mutate (variable = str_remove(variable, "class, ")) %>%
  filter (reduction != 0) %>%
  arrange (desc (reduction)) %>%
  slice (10:nrow (.)) %>%
  summarise (reduction = sum (reduction),
             selfreq = sum (selfreq)) 

vp_df[10,] <- c(round (vp_df2$reduction, 2), "Others", round (vp_df2$selfreq, 2))

vp_df$variable <- factor (vp_df$variable, levels = vp_df$variable)
vp_df <- vp_df %>%
  mutate (variable = fct_rev(variable),
          selfreq = paste0(as.numeric (selfreq) *100, "%"))

f1 <- ggplot (vp_df) +
  geom_bar(aes (x = variable, y = reduction), stat = "identity") +
  geom_text(aes (x = variable, y = reduction, label = selfreq), hjust=-0.25) + 
  coord_flip() +
  labs (x = "Variables",
        y = "In-bag risk reduction") +
  cowplot::theme_cowplot()

tiff ("../manuscript/fig1.tiff", units = "in", height = 5, width = 7, res = 100)
  f1
dev.off()

```

## Interpretable plots

```{r}
top4_vars <- as.character (vp_df$variable[1:4])

# cumul. probability for median curve (mean curve is zero due to scaling)
preds <- pred_for_all(which)
# log-odds 
preds_odds <- pred_for_all(which, type = "link")

# plot for probabilities

p1 <- preds %>%
  filter (feature %in% top4_vars) %>%
  mutate (feature = factor (feature, levels = top4_vars),
          class = factor (class, labels = c("KL0", "KL2", "KL3", "KL4"))) %>%
  ggplot(aes(x = cycle, y = value, color = class)) + 
  geom_line() + facet_wrap(~ feature#, consider using scales = "free" 
                                    # -> progress better visible, but 
                                    #    small differences maybe not relevant
                           ) +  
  scale_color_manual(values = c("black", "blue", "darkgreen", "red")) + 
  cowplot::theme_cowplot() + 
  ylab("Probability for Class") + 
  xlab("Stance phase (%)")

tiff ("../manuscript/fig2.tiff", units = "in", height = 5, width = 9, res = 100)
  p1
dev.off()

```


```{r}
source("https://raw.githubusercontent.com/achekroud/nomogrammer/master/nomogrammer.r")
```

